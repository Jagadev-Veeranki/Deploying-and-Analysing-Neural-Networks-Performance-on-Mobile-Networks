{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n61FoQMj9pa-",
        "outputId": "abc9a1bf-848f-4aac-b11a-0a3185946841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 242s 500ms/step - loss: 0.1515 - accuracy: 0.9527 - precision: 0.9709 - recall: 0.9402\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 221s 472ms/step - loss: 0.0394 - accuracy: 0.9880 - precision: 0.9891 - recall: 0.9871\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 229s 488ms/step - loss: 0.0257 - accuracy: 0.9920 - precision: 0.9925 - recall: 0.9915\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 224s 478ms/step - loss: 0.0196 - accuracy: 0.9937 - precision: 0.9941 - recall: 0.9934\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 221s 471ms/step - loss: 0.0145 - accuracy: 0.9953 - precision: 0.9955 - recall: 0.9951\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 221s 470ms/step - loss: 0.0107 - accuracy: 0.9964 - precision: 0.9966 - recall: 0.9963\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 221s 471ms/step - loss: 0.0103 - accuracy: 0.9966 - precision: 0.9966 - recall: 0.9964\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 219s 467ms/step - loss: 0.0093 - accuracy: 0.9967 - precision: 0.9967 - recall: 0.9966\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 219s 466ms/step - loss: 0.0074 - accuracy: 0.9977 - precision: 0.9979 - recall: 0.9977\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 219s 467ms/step - loss: 0.0042 - accuracy: 0.9987 - precision: 0.9988 - recall: 0.9987\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.0303 - accuracy: 0.9921 - precision: 0.9923 - recall: 0.9921\n",
            "Test Accuracy: 0.9921000003814697\n",
            "Precision: 0.9922984838485718\n",
            "Recall: 0.9921000003814697\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the input data\n",
        "X_train = X_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "X_test = X_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the target labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", metrics[1])\n",
        "print(\"Precision:\", metrics[2])\n",
        "print(\"Recall:\", metrics[3])\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to file\n",
        "with open(\"mnist_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KbAXdwgCbnp"
      },
      "source": [
        "Compression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWUZV4eYvKak",
        "outputId": "c916065c-500d-460a-af52-4bed7d3ed189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Installing collected packages: tensorflow_model_optimization\n",
            "Successfully installed tensorflow_model_optimization-0.8.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "422/422 [==============================] - 208s 481ms/step - loss: 0.1546 - accuracy: 0.9526 - val_loss: 0.0469 - val_accuracy: 0.9872\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 212s 503ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.0361 - val_accuracy: 0.9897\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 215s 509ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.0407 - val_accuracy: 0.9893\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 214s 506ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0303 - val_accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 210s 498ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0302 - val_accuracy: 0.9913\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 209s 495ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0272 - val_accuracy: 0.9925\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 207s 491ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.0325 - val_accuracy: 0.9927\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 206s 488ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0446 - val_accuracy: 0.9918\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 198s 469ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0388 - val_accuracy: 0.9942\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 205s 485ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0382 - val_accuracy: 0.9928\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow_model_optimization.sparsity.keras import prune_low_magnitude\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "from tensorflow_model_optimization.sparsity.keras import PolynomialDecay\n",
        "from tensorflow_model_optimization.sparsity.keras import UpdatePruningStep\n",
        "from tensorflow_model_optimization.sparsity.keras import PruningSummaries\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
        "X_test = X_test.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Set up pruning\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "num_train_samples = X_train.shape[0]\n",
        "end_step = np.ceil(num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "pruning_schedule = PolynomialDecay(initial_sparsity=0.10, final_sparsity=0.50, begin_step=0, end_step=end_step)\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n",
        "\n",
        "# Compile the pruned model\n",
        "pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for pruning\n",
        "callbacks = [\n",
        "    UpdatePruningStep(),\n",
        "    PruningSummaries(log_dir='/tmp/logs', update_freq='epoch')\n",
        "]\n",
        "\n",
        "# Train the pruned model\n",
        "pruned_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks)\n",
        "\n",
        "# Strip the pruning wrappers for final model\n",
        "model_for_export = strip_pruning(pruned_model)\n",
        "\n",
        "# Convert to TensorFlow Lite with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the compressed model\n",
        "with open('mnist_model_compressed.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}